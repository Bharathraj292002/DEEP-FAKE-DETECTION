DeepFake Detection Using Residual Noise, Warping Artifacts, and Blur Effects :
This repository contains the implementation of a deep fake detection technique designed to identify various types of deep fake images. The proposed method leverages three common traces generated by deep fakes: residual noise, warping artifacts, and blur effects. By combining these detection strategies, our approach achieves superior performance compared to existing detection networks.

Features :
Residual Noise Detection: Utilizes a network designed for steganalysis to detect pixel-wise residual-noise traces left by deep fake processes.
Warping Artifacts Detection: Extracts landmark patches from semantic facial regions to identify unnatural deformations in deep fake images.
Blur Effects Detection: Applies features from various image quality measurement tools to capture statistical characteristics of blur-like effects in deep fake images.

Methodology :
1) Residual Noise Detection: The base network, designed for steganalysis, is adopted to detect residual noise in images.
Warping Artifacts Detection: High-level features are captured by focusing on landmark patches in the primary facial regions where deep fake deformations often occur.
2) Blur Effects Detection: Image quality measurement (IQM) features are used to detect blur-like effects resulting from deep fake manipulations.

Results :
Our method demonstrates superior performance and stability across different datasets containing various types of deep fake images, including face swaps, puppet-master, and attribute changes. The proposed network outperforms existing detection techniques and can be integrated into deep fake video detection pipelines by analyzing frames individually.

Future Work :
We aim to extend this approach to include deep fake video detection methods, enhancing robustness against signal- and time-based attacks.

Usage : 
Instructions on how to use the deep fake detection model will be provided here. This will include steps to set up the environment, train the model, and test it on sample images or video frames.

Contributions :
Contributions are welcome! If you have any ideas to improve this project or find any issues, please submit a pull request or open an issue.

License :
This project is licensed under the MIT License.
